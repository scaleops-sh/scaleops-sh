# Default values for scaleops.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: ghcr.io/scaleops-sh/scaleops
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: latest

imagePullSecrets:
  - scaleops

imageCredentials:
  enabled: true
  name: scaleops
  username: github_user
  password: github_token

nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# We usually recommend not to specify default resources and to leave this as a conscious
# choice for the user. This also increases chances charts run on environments with little
# resources, such as Minikube. If you do want to specify resources, uncomment the following
# lines, adjust them as necessary, and remove the curly braces after 'resources:'.
resources:
  requests:
    cpu: 150m
    memory: 200Mi
  limits:
    cpu: 300m
    memory: 400Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}

clusterRole:
  name: scaleops
  enabled: true

prometheusUrl: "http://scaleops-prometheus-server:8080"
prometheusEnabled: true
config:
  enabled: true
  configMapName: scaleops-config
  value: |-
    apiVersion: analysis.crane.io/v1alpha1
    kind: ConfigSet
    configs:
      - targets: []
        properties:
          resource.cpu-request-percentile: "0.98"
          ehpa.deployment-min-replicas: "1"
          ehpa.statefulset-min-replicas: "1"
          ehpa.workload-min-replicas: "1"
          ehpa.pod-min-ready-seconds: "30"
          ehpa.pod-available-ratio: "0.5"
          ehpa.default-min-replicas: "2"
          ehpa.max-replicas-factor: "3"
          ehpa.min-cpu-usage-threshold: "10"
          ehpa.fluctuation-threshold: "1.5"
          ehpa.min-cpu-target-utilization: "30"
          ehpa.max-cpu-target-utilization: "75"
          ehpa.reference-hpa: "true"

prometheus:
  pushgateway:
    pushgateway:
      enabled: false
    alertmanager:
    enabled: false
  serverFiles:
    ## Records configuration
    ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/
    recording_rules.yml:
      groups:
        - name: costs.rules
          interval: 3600s
          rules:
            - expr: |
                sum(label_replace(irate(container_cpu_usage_seconds_total{container!="POD", container!="",image!=""}[1h]), "node", "$1", "instance",  "(.*)")) by (container, pod, node, namespace) * on (node) group_left() avg(avg_over_time(node_cpu_hourly_cost[1h])) by (node)
              record: namespace:container_cpu_usage_costs_hourly:sum_rate
            - expr: |
                sum(label_replace(avg_over_time(container_memory_working_set_bytes{container!="POD",container!="",image!=""}[1h]), "node", "$1", "instance",  "(.*)")) by (container, pod, node, namespace) / 1024.0 / 1024.0 / 1024.0 * on (node) group_left() avg(avg_over_time(node_ram_hourly_cost[1h])) by (node)
              record: namespace:container_memory_usage_costs_hourly:sum_rate
            - expr: |
                avg(avg_over_time(node_cpu_hourly_cost[1h])) by (node)
              record: node:node_cpu_hourly_cost:avg
            - expr: |
                avg(avg_over_time(node_ram_hourly_cost[1h])) by (node)
              record: node:node_ram_hourly_cost:avg
            - expr: |
                avg(avg_over_time(node_total_hourly_cost[1h])) by (node)
              record: node:node_total_hourly_cost:avg
        - name: scheduler.rules.30s
          interval: 30s
          rules:
            - record: cpu_usage_active
              expr: 100 - (avg by (instance) (irate(node_cpu_seconds_total{mode="idle"}[90s])) * 100)
            - record: mem_usage_active
              expr: 100*(1-node_memory_MemAvailable_bytes/node_memory_MemTotal_bytes)
        - name: scheduler.rules.1m
          interval: 1m
          rules:
            - record: cpu_usage_avg_5m
              expr: avg_over_time(cpu_usage_active[5m])
            - record: mem_usage_avg_5m
              expr: avg_over_time(mem_usage_active[5m])
        - name: scheduler.rules.5m
          interval: 5m
          rules:
            - record: cpu_usage_max_avg_1h
              expr: max_over_time(cpu_usage_avg_5m[1h])
            - record: cpu_usage_max_avg_1d
              expr: max_over_time(cpu_usage_avg_5m[1d])
            - record: mem_usage_max_avg_1h
              expr: max_over_time(mem_usage_avg_5m[1h])
            - record: mem_usage_max_avg_1d
              expr: max_over_time(mem_usage_avg_5m[1d])


  # adds additional scrape configs to prometheus.yml
  # must be a string so you have to add a | after extraScrapeConfigs:
  # example adds prometheus-blackbox-exporter scrape config
#  extraScrapeConfigs: |-
#    # this is used to scrape fadvisor
#    - job_name: "fadvisor"
#      honor_timestamps: true
#      scheme: http
#      metrics_path: /metrics
#      static_configs:
#        - targets: ['fadvisor:8081']
  

  server:
    enabled: true
    persistentVolume:
      enabled: false
    service:
      annotations: { }
      labels: { }
      clusterIP: ""

      ## List of IP addresses at which the Prometheus server service is available
      ## Ref: https://kubernetes.io/docs/user-guide/services/#external-ips
      ##
      externalIPs: [ ]

      loadBalancerIP: ""
      loadBalancerSourceRanges: [ ]
      servicePort: 8080
      sessionAffinity: None
      type: ClusterIP

  nodeExporter:
    hostRootfs: false

  kubeStateMetrics:
    ## If false, kube-state-metrics sub-chart will not be installed
    ##
    enabled: true

  ## kube-state-metrics sub-chart configurable values
  ## Please see https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-state-metrics
  ##
  kube-state-metrics:
    prometheus:
      monitor:
        honorLabels: true
    image:
      repository: ccr.ccs.tencentyun.com/tkeimages/kube-state-metrics
      pullPolicy: IfNotPresent
      tag: "2.2.4"
    extraArgs:
      - --metric-labels-allowlist=pods=[*]
